{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import ndcg_score\n",
    "import multiprocessing as mp\n",
    "\n",
    "articles = np.load('news/articles.npy')\n",
    "article_ids = articles[:, 0].astype(int)\n",
    "article_embeddings = articles[:, 1:]  # shape: (364047, 253)\n",
    "\n",
    "article_embedding_dict = {aid: emb for aid, emb in zip(article_ids, article_embeddings)}\n",
    "\n",
    "train_click_log = np.load('news/train_click_log.npy')\n",
    "\n",
    "user_embeddings = defaultdict(list)\n",
    "for user_id, art_id in train_click_log:\n",
    "    user_embeddings[int(user_id)].append(article_embedding_dict.get(int(art_id)))\n",
    "\n",
    "user_embedding_dict = {}\n",
    "for user_id, emb_list in user_embeddings.items():\n",
    "    emb_list = [emb for emb in emb_list if emb is not None]\n",
    "    if emb_list:\n",
    "        user_embedding_dict[user_id] = np.mean(emb_list, axis=0)\n",
    "    else:\n",
    "        user_embedding_dict[user_id] = np.zeros(article_embeddings.shape[1])\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "group = []  # for ranking objective: list of group sizes (per user)\n",
    "\n",
    "user_pos = defaultdict(set)\n",
    "for user_id, art_id in train_click_log:\n",
    "    user_pos[int(user_id)].add(int(art_id))\n",
    "\n",
    "all_article_ids = list(set(article_ids))\n",
    "\n",
    "def process_user(args):\n",
    "    user_id, pos_articles = args\n",
    "    u_emb = user_embedding_dict.get(user_id)\n",
    "    if u_emb is None:\n",
    "        return None, None, 0\n",
    "    user_features = []\n",
    "    user_labels = []\n",
    "    \n",
    "    pos_articles = list(pos_articles)\n",
    "    n_pos = len(pos_articles)\n",
    "    \n",
    "    # Generate negatives in one batch for this user\n",
    "    neg_samples_batch = np.random.choice(all_article_ids, size=3 * n_pos, replace=False)\n",
    "    neg_samples_batch = neg_samples_batch.reshape(n_pos, 3)\n",
    "    \n",
    "    for idx, pos_art in enumerate(pos_articles):\n",
    "        pos_emb = article_embedding_dict.get(pos_art)\n",
    "        if pos_emb is None:\n",
    "            continue\n",
    "        # Positive sample\n",
    "        feat = np.concatenate([u_emb, pos_emb])\n",
    "        user_features.append(feat)\n",
    "        user_labels.append(1)\n",
    "        # Negative samples for this positive sample\n",
    "        for neg_art in neg_samples_batch[idx]:\n",
    "            neg_emb = article_embedding_dict.get(int(neg_art))\n",
    "            if neg_emb is None:\n",
    "                continue\n",
    "            feat_neg = np.concatenate([u_emb, neg_emb])\n",
    "            user_features.append(feat_neg)\n",
    "            user_labels.append(0)\n",
    "    return user_features, user_labels, len(user_features)\n",
    "\n",
    "# Prepare arguments for each user\n",
    "args_list = list(user_pos.items())\n",
    "\n",
    "# Create a pool of processes (using all available CPU cores)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "results = pool.map(process_user, args_list)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "# Collect and combine results\n",
    "X_train = []\n",
    "y_train = []\n",
    "group = []\n",
    "for features, labels, grp in results:\n",
    "    if features is not None:\n",
    "        X_train.extend(features)\n",
    "        y_train.extend(labels)\n",
    "        group.append(grp)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtrain.set_group(group)\n",
    "\n",
    "params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eta': 0.1,\n",
    "    'gamma': 1.0,\n",
    "    'min_child_weight': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'eval_metric': 'ndcg',\n",
    "    'seed': 42,\n",
    "    'verbosity': 1\n",
    "}\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG@50: 0.0136\n"
     ]
    }
   ],
   "source": [
    "test_click_log = np.load('news/test_click_log.npy')\n",
    "\n",
    "user_embeddings = defaultdict(list)\n",
    "test_user_ground_truth = {}\n",
    "for user_id, art_id in test_click_log:\n",
    "    user_embeddings[int(user_id)].append(article_embedding_dict.get(int(art_id)))\n",
    "    test_user_ground_truth[int(user_id)] = int(art_id)\n",
    "\n",
    "user_recommendations = np.load('news/user_recommendations.npy', allow_pickle=True).item()\n",
    "\n",
    "ndcg_scores = []\n",
    "\n",
    "for user_id, candidates in user_recommendations.items():\n",
    "    if len(candidates) == 0: continue\n",
    "    user_id = int(user_id)\n",
    "    u_emb = user_embedding_dict.get(user_id)\n",
    "    if u_emb is None:\n",
    "        u_emb = np.zeros(article_embeddings.shape[1])\n",
    "    \n",
    "    candidate_features = []\n",
    "    for art_id in candidates:\n",
    "        art_emb = article_embedding_dict.get(int(art_id))\n",
    "        if art_emb is None:\n",
    "            art_emb = np.zeros(article_embeddings.shape[1])\n",
    "        feat = np.concatenate([u_emb, art_emb])\n",
    "        candidate_features.append(feat)\n",
    "    \n",
    "    candidate_features = np.vstack(candidate_features)\n",
    "    dtest = xgb.DMatrix(candidate_features)\n",
    "    scores = model.predict(dtest)\n",
    "    \n",
    "    ranked_idx = np.argsort(-scores)\n",
    "    ranked_candidates = np.array(candidates)[ranked_idx]\n",
    "    \n",
    "    ground_truth = test_user_ground_truth.get(user_id)\n",
    "    relevance = [1 if int(art) == ground_truth else 0 for art in ranked_candidates]\n",
    "    score = ndcg_score([relevance[:50]], [np.arange(len(relevance[:50]), 0, -1)])\n",
    "    ndcg_scores.append(score)\n",
    "\n",
    "avg_ndcg = np.mean(ndcg_scores)\n",
    "print(f'Average NDCG@50: {avg_ndcg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 0: 258 keys\n",
      "Length 2: 1 keys\n",
      "Length 3: 16 keys\n",
      "Length 19: 13 keys\n",
      "Length 23: 1 keys\n",
      "Length 26: 4 keys\n",
      "Length 27: 4 keys\n",
      "Length 38: 8 keys\n",
      "Length 42: 2 keys\n",
      "Length 44: 3 keys\n",
      "Length 48: 1 keys\n",
      "Length 63: 6 keys\n",
      "Length 70: 1 keys\n",
      "Length 72: 7 keys\n",
      "Length 78: 1 keys\n",
      "Length 88: 4 keys\n",
      "Length 94: 1 keys\n",
      "Length 98: 2 keys\n",
      "Length 99: 1 keys\n",
      "Length 107: 2 keys\n",
      "Length 111: 1 keys\n",
      "Length 112: 1 keys\n",
      "Length 116: 1 keys\n",
      "Length 123: 7 keys\n",
      "Length 124: 1 keys\n",
      "Length 126: 2 keys\n",
      "Length 129: 1 keys\n",
      "Length 139: 1 keys\n",
      "Length 141: 2 keys\n",
      "Length 146: 1 keys\n",
      "Length 148: 6 keys\n",
      "Length 151: 1 keys\n",
      "Length 155: 2 keys\n",
      "Length 161: 5 keys\n",
      "Length 164: 34 keys\n",
      "Length 173: 6 keys\n",
      "Length 174: 2 keys\n",
      "Length 189: 2 keys\n",
      "Length 194: 2 keys\n",
      "Length 199: 1 keys\n",
      "Length 202: 1 keys\n",
      "Length 208: 9 keys\n",
      "Length 214: 1 keys\n",
      "Length 215: 15 keys\n",
      "Length 217: 1 keys\n",
      "Length 219: 17 keys\n",
      "Length 224: 1 keys\n",
      "Length 225: 10 keys\n",
      "Length 229: 2 keys\n",
      "Length 231: 5 keys\n",
      "Length 234: 1 keys\n",
      "Length 239: 11 keys\n",
      "Length 300: 2 keys\n",
      "Length 315: 4 keys\n",
      "Length 324: 2 keys\n",
      "Length 329: 34 keys\n",
      "Length 350: 4 keys\n",
      "Length 365: 4 keys\n",
      "Length 367: 1 keys\n",
      "Length 370: 3 keys\n",
      "Length 384: 9 keys\n",
      "Length 389: 53 keys\n",
      "Length 390: 2 keys\n",
      "Length 409: 77 keys\n",
      "Length 410: 1 keys\n",
      "Length 412: 34 keys\n",
      "Length 414: 1 keys\n",
      "Length 419: 6 keys\n",
      "Length 437: 7 keys\n",
      "Length 448: 22 keys\n",
      "Length 458: 18 keys\n",
      "Length 468: 1 keys\n",
      "Length 475: 2 keys\n",
      "Length 483: 1 keys\n",
      "Length 486: 2 keys\n",
      "Length 493: 60 keys\n",
      "Length 494: 1 keys\n",
      "Length 500: 3 keys\n",
      "Length 503: 3 keys\n",
      "Length 507: 8 keys\n",
      "Length 523: 4 keys\n",
      "Length 546: 4 keys\n",
      "Length 553: 2 keys\n",
      "Length 562: 2 keys\n",
      "Length 568: 8 keys\n",
      "Length 571: 2 keys\n",
      "Length 578: 18 keys\n",
      "Length 623: 1 keys\n",
      "Length 638: 1 keys\n",
      "Length 670: 1 keys\n",
      "Length 673: 3 keys\n",
      "Length 696: 2 keys\n",
      "Length 701: 55 keys\n",
      "Length 705: 2 keys\n",
      "Length 735: 5 keys\n",
      "Length 742: 1 keys\n",
      "Length 750: 3 keys\n",
      "Length 758: 2 keys\n",
      "Length 796: 5 keys\n",
      "Length 805: 144 keys\n",
      "Length 816: 1 keys\n",
      "Length 833: 2 keys\n",
      "Length 843: 6 keys\n",
      "Length 865: 3 keys\n",
      "Length 876: 1 keys\n",
      "Length 877: 1 keys\n",
      "Length 880: 2 keys\n",
      "Length 893: 5 keys\n",
      "Length 907: 1 keys\n",
      "Length 908: 17 keys\n",
      "Length 909: 1 keys\n",
      "Length 914: 1 keys\n",
      "Length 917: 2 keys\n",
      "Length 918: 15506 keys\n",
      "Length 933: 2 keys\n",
      "Length 937: 3 keys\n",
      "Length 942: 2 keys\n",
      "Length 954: 1 keys\n",
      "Length 959: 1 keys\n",
      "Length 962: 2 keys\n",
      "Length 965: 4 keys\n",
      "Length 975: 2 keys\n",
      "Length 980: 28 keys\n",
      "Length 981: 1 keys\n",
      "Length 985: 2 keys\n",
      "Length 1009: 21 keys\n",
      "Length 1034: 1 keys\n",
      "Length 1039: 1 keys\n",
      "Length 1053: 1 keys\n",
      "Length 1054: 3 keys\n",
      "Length 1058: 4 keys\n",
      "Length 1064: 1 keys\n",
      "Length 1082: 1 keys\n",
      "Length 1097: 19 keys\n",
      "Length 1112: 1 keys\n",
      "Length 1127: 1 keys\n",
      "Length 1151: 2 keys\n",
      "Length 1157: 1 keys\n",
      "Length 1167: 3 keys\n",
      "Length 1192: 12 keys\n",
      "Length 1193: 7 keys\n",
      "Length 1199: 3 keys\n",
      "Length 1222: 5 keys\n",
      "Length 1223: 7 keys\n",
      "Length 1225: 3 keys\n",
      "Length 1228: 2 keys\n",
      "Length 1234: 1 keys\n",
      "Length 1242: 13 keys\n",
      "Length 1259: 1 keys\n",
      "Length 1268: 131 keys\n",
      "Length 1270: 2 keys\n",
      "Length 1274: 1 keys\n",
      "Length 1290: 1 keys\n",
      "Length 1294: 11 keys\n",
      "Length 1302: 2 keys\n",
      "Length 1325: 2 keys\n",
      "Length 1343: 5 keys\n",
      "Length 1344: 1 keys\n",
      "Length 1347: 1 keys\n",
      "Length 1423: 1 keys\n",
      "Length 1453: 2 keys\n",
      "Length 1490: 3 keys\n",
      "Length 1508: 6 keys\n",
      "Length 1532: 1 keys\n",
      "Length 1558: 6 keys\n",
      "Length 1568: 1 keys\n",
      "Length 1605: 3 keys\n",
      "Length 1622: 86 keys\n",
      "Length 1629: 5 keys\n",
      "Length 1709: 7 keys\n",
      "Length 1784: 3 keys\n",
      "Length 1798: 9 keys\n",
      "Length 1808: 6 keys\n",
      "Length 1828: 5 keys\n",
      "Length 1876: 16 keys\n",
      "Length 1881: 1 keys\n",
      "Length 1885: 4 keys\n",
      "Length 1887: 8 keys\n",
      "Length 1932: 131 keys\n",
      "Length 2010: 12255 keys\n",
      "Length 2017: 16 keys\n",
      "Length 2042: 229 keys\n",
      "Length 2290: 16 keys\n",
      "Length 2303: 3 keys\n",
      "Length 2365: 8 keys\n",
      "Length 2412: 10 keys\n",
      "Length 2421: 37 keys\n",
      "Length 2426: 22 keys\n",
      "Length 2485: 8 keys\n",
      "Length 2560: 106 keys\n",
      "Length 2596: 22 keys\n",
      "Length 2616: 35 keys\n",
      "Length 2736: 72 keys\n",
      "Length 2745: 3 keys\n",
      "Length 2796: 8 keys\n",
      "Length 2798: 6 keys\n",
      "Length 2901: 82 keys\n",
      "Length 3070: 232 keys\n",
      "Length 4220: 161 keys\n",
      "Length 4575: 497 keys\n",
      "Length 6475: 18881 keys\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "lengths = [len(arr) for arr in user_recommendations.values()]\n",
    "\n",
    "# Count the frequency of each length.\n",
    "length_distribution = Counter(lengths)\n",
    "\n",
    "# Print out the distribution.\n",
    "for length, count in sorted(length_distribution.items()):\n",
    "    print(f\"Length {length}: {count} keys\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
